"""
åŠ å¯†è´§å¸å¸‚åœºæƒ…ç»ªè¿½è¸ªå™¨
Crypto Sentiment Tracker v1.0

ä¸€ä¸ªåŸåˆ›çš„ã€å¯æ‰§è¡Œçš„é‡‘èå¸‚åœºæƒ…ç»ªåˆ†ææ¡†æ¶
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Tuple, Optional
import json


class CryptoSentimentTracker:
    """
    ç»¼åˆåŠ å¯†è´§å¸å¸‚åœºæƒ…ç»ªåˆ†æå™¨
    
    ä½¿ç”¨æ–¹æ³•:
        tracker = CryptoSentimentTracker()
        sentiment = tracker.get_comprehensive_sentiment()
        print(f"å½“å‰æƒ…ç»ª: {sentiment['overall']}")
    """
    
    def __init__(self):
        self.weights = {
            'social': 0.30,
            'search': 0.25,
            'onchain': 0.25,
            'volatility': 0.20
        }
        self.sentiment_levels = {
            (0, 20): "æåº¦ææƒ§ (Extreme Fear)",
            (20, 40): "ææƒ§ (Fear)",
            (40, 60): "ä¸­æ€§ (Neutral)",
            (60, 80): "è´ªå©ª (Greed)",
            (80, 100): "æåº¦è´ªå©ª (Extreme Greed)"
        }
    
    # ==================== 1. ç¤¾äº¤åª’ä½“çƒ­åº¦ ====================
    
    def calculate_social_heat(self, mentions_data: Dict) -> float:
        """
        è®¡ç®—ç¤¾äº¤åª’ä½“çƒ­åº¦æŒ‡æ•° (0-100)
        
        Args:
            mentions_data: {
                'positive_mentions': int,
                'negative_mentions': int,
                'total_mentions': int
            }
        """
        positive = mentions_data.get('positive_mentions', 0)
        negative = mentions_data.get('negative_mentions', 0)
        total = mentions_data.get('total_mentions', 1)
        
        # æƒ…ç»ªå‡€å€¼å¾—åˆ† (-1 åˆ° 1)
        net_sentiment = (positive - negative) / total
        
        # çƒ­åº¦å› å­ (æ€»æåŠé‡çš„å¯¹æ•°ç¼©æ”¾)
        volume_factor = min(np.log10(total + 1) / 6, 1.0)
        
        # ç»¼åˆå¾—åˆ†æ˜ å°„åˆ° 0-100
        raw_score = (net_sentiment + 1) / 2  # æ˜ å°„åˆ° 0-1
        heat_score = raw_score * 50 + volume_factor * 50
        
        return round(min(max(heat_score, 0), 100), 2)
    
    def analyze_twitter_sentiment(self, tweets: List[str]) -> Dict:
        """
        ç®€å•çš„Twitteræƒ…ç»ªåˆ†æ
        
        æ­£é¢è¯åº“å’Œè´Ÿé¢è¯åº“åŸºäºåŠ å¯†è´§å¸ç¤¾åŒºå¸¸ç”¨è¯­
        """
        positive_words = [
            'moon', 'bull', 'bullish', 'breakout', 'accumulate', 'hodl', 
            'diamond hands', 'pump', ' ATH', 'all time high', 'buy the dip',
            'generational wealth', 'rocket', 'lambo', 'wagmi', 'gm'
        ]
        
        negative_words = [
            'crash', 'bear', 'bearish', 'dump', 'panic', 'sell', 'exit',
            'rug', 'scam', 'dead', 'bottom', 'capitulation', 'paper hands',
            'ngmi', 'rekt', 'liquidated'
        ]
        
        positive_count = sum(1 for tweet in tweets 
                           for word in positive_words if word in tweet.lower())
        negative_count = sum(1 for tweet in tweets 
                           for word in negative_words if word in tweet.lower())
        
        return {
            'positive_mentions': positive_count,
            'negative_mentions': negative_count,
            'total_mentions': len(tweets)
        }
    
    # ==================== 2. æœç´¢è¶‹åŠ¿åˆ†æ ====================
    
    def calculate_search_momentum(self, trend_data: Dict) -> float:
        """
        è®¡ç®—æœç´¢è¶‹åŠ¿åŠ¨é‡ (0-100)
        
        Args:
            trend_data: {
                'buy_bitcoin': [å‘¨æœç´¢é‡åˆ—è¡¨],
                'crypto_crash': [å‘¨æœç´¢é‡åˆ—è¡¨],
                'altcoin_season': [å‘¨æœç´¢é‡åˆ—è¡¨]
            }
        """
        # è®¡ç®—å„å…³é”®è¯çš„å‘¨ç¯æ¯”å˜åŒ–
        def growth_rate(series):
            if len(series) < 2 or series[-2] == 0:
                return 0
            return (series[-1] - series[-2]) / series[-2]
        
        buy_growth = growth_rate(trend_data.get('buy_bitcoin', [0, 0]))
        crash_growth = growth_rate(trend_data.get('crypto_crash', [0, 0]))
        alt_growth = growth_rate(trend_data.get('altcoin_season', [0, 0]))
        
        # ä¹°å…¥å…´è¶£ä¸Šå‡ = çœ‹æ¶¨ä¿¡å·
        # å´©ç›˜æœç´¢ä¸Šå‡ = çœ‹è·Œä¿¡å·
        # å±±å¯¨å­£æœç´¢ä¸Šå‡ = é£é™©åå¥½é«˜
        
        sentiment_score = (
            buy_growth * 40 +           # ä¹°å…¥å…´è¶£æƒé‡
            (1 - crash_growth) * 30 +   # å´©ç›˜ææƒ§åå‘æƒé‡
            alt_growth * 30             # å±±å¯¨å­£çƒ­åº¦
        )
        
        # æ˜ å°„åˆ° 0-100
        normalized = (sentiment_score + 1) * 50
        return round(min(max(normalized, 0), 100), 2)
    
    # ==================== 3. é“¾ä¸Šæ•°æ®åˆ†æ ====================
    
    def analyze_onchain_signals(self, chain_data: Dict) -> float:
        """
        åˆ†æé“¾ä¸Šä¿¡å· (0-100)
        
        Args:
            chain_data: {
                'exchange_netflow': float,  # æ­£å€¼=æµå…¥äº¤æ˜“æ‰€ï¼Œè´Ÿå€¼=æµå‡º
                'lth_supply_change': float, # é•¿æœŸæŒæœ‰è€…æŒä»“å˜åŒ–%
                'sopr': float               # èŠ±è´¹è¾“å‡ºåˆ©æ¶¦ç‡ (>1ç›ˆåˆ©ï¼Œ<1äºæŸ)
            }
        """
        signals = []
        
        # ä¿¡å·1: äº¤æ˜“æ‰€å‡€æµå‡º = æŒæœ‰è€…è½¬ç§»å»å†·é’±åŒ… = çœ‹æ¶¨
        netflow = chain_data.get('exchange_netflow', 0)
        if netflow < -1000:  # å¤§é¢æµå‡º
            signals.append(80)
        elif netflow < 0:
            signals.append(60)
        else:
            signals.append(40)
        
        # ä¿¡å·2: é•¿æœŸæŒæœ‰è€…å¢æŒ = çœ‹æ¶¨
        lth_change = chain_data.get('lth_supply_change', 0)
        if lth_change > 1:
            signals.append(75)
        elif lth_change > 0:
            signals.append(60)
        else:
            signals.append(45)
        
        # ä¿¡å·3: SOPRæŒ‡æ ‡
        sopr = chain_data.get('sopr', 1.0)
        if sopr > 1.05:  # å¤§é‡è·åˆ©äº†ç»“ï¼Œå¯èƒ½é¡¶éƒ¨
            signals.append(40)
        elif sopr > 1.0:  # å¥åº·è·åˆ©
            signals.append(65)
        elif sopr < 0.95:  # äºæŸæŠ›å”®ï¼Œå¯èƒ½åº•éƒ¨
            signals.append(70)
        else:
            signals.append(50)
        
        return round(np.mean(signals), 2)
    
    # ==================== 4. æ³¢åŠ¨ç‡åˆ†æ ====================
    
    def calculate_volatility_sentiment(self, price_data: List[float]) -> float:
        """
        åŸºäºæ³¢åŠ¨ç‡çš„é€†å‘æƒ…ç»ªæŒ‡æ ‡ (0-100)
        
        é€»è¾‘: é«˜æ³¢åŠ¨ç‡é€šå¸¸ä¼´éšææƒ§ï¼Œä½æ³¢åŠ¨ç‡å¯èƒ½é¢„ç¤ºå˜ç›˜
        """
        if len(price_data) < 30:
            return 50
        
        # è®¡ç®—30æ—¥æ³¢åŠ¨ç‡
        returns = pd.Series(price_data).pct_change().dropna()
        current_vol = returns.tail(7).std() * np.sqrt(365)  # å¹´åŒ–
        avg_vol = returns.std() * np.sqrt(365)
        
        # æ³¢åŠ¨ç‡åç¦»åº¦
        vol_deviation = (current_vol - avg_vol) / avg_vol
        
        # é«˜æ³¢åŠ¨ç‡ = ææƒ§ (ä½åˆ†)
        # æä½æ³¢åŠ¨ç‡ = å‹æŠ‘åçš„çˆ†å‘å¯èƒ½ (ä¸­é«˜åˆ†)
        if vol_deviation > 0.5:  # æ³¢åŠ¨ç‡æ¿€å¢
            score = 30
        elif vol_deviation > 0.2:
            score = 45
        elif vol_deviation < -0.3:  # æ³¢åŠ¨ç‡æä½
            score = 65  # å˜ç›˜å‰å…†
        else:
            score = 55
        
        return score
    
    # ==================== ç»¼åˆè®¡ç®— ====================
    
    def get_comprehensive_sentiment(self, data: Dict = None) -> Dict:
        """
        è·å–ç»¼åˆå¸‚åœºæƒ…ç»ªè¯„åˆ†
        
        Args:
            data: å¯é€‰çš„è‡ªå®šä¹‰æ•°æ®ï¼Œä¸ä¼ åˆ™ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        
        Returns:
            {
                'overall': str,           # æƒ…ç»ªæè¿°
                'score': float,           # 0-100åˆ†æ•°
                'components': Dict,       # å„åˆ†é¡¹å¾—åˆ†
                'signal': str,            # äº¤æ˜“ä¿¡å·
                'timestamp': str
            }
        """
        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”æ¥å…¥çœŸå®APIï¼‰
        sample_data = data or {
            'social': {
                'positive_mentions': 12500,
                'negative_mentions': 8300,
                'total_mentions': 45000
            },
            'search': {
                'buy_bitcoin': [45, 52, 48, 61, 58],
                'crypto_crash': [30, 35, 42, 38, 33],
                'altcoin_season': [25, 28, 35, 45, 52]
            },
            'onchain': {
                'exchange_netflow': -2500,  # å‡€æµå‡º
                'lth_supply_change': 0.8,   # é•¿æœŸæŒæœ‰è€…å¢æŒ0.8%
                'sopr': 1.02                # å°å¹…ç›ˆåˆ©
            },
            'price_history': [42000, 43500, 42800, 45100, 46700, 
                            45800, 47200, 48900, 47600, 49500] * 3
        }
        
        # è®¡ç®—å„åˆ†é¡¹
        social_score = self.calculate_social_heat(sample_data['social'])
        search_score = self.calculate_search_momentum(sample_data['search'])
        onchain_score = self.analyze_onchain_signals(sample_data['onchain'])
        vol_score = self.calculate_volatility_sentiment(sample_data['price_history'])
        
        # åŠ æƒç»¼åˆ
        composite = (
            social_score * self.weights['social'] +
            search_score * self.weights['search'] +
            onchain_score * self.weights['onchain'] +
            vol_score * self.weights['volatility']
        )
        
        # ç¡®å®šæƒ…ç»ªç­‰çº§
        sentiment_desc = "æœªçŸ¥"
        for (low, high), desc in self.sentiment_levels.items():
            if low <= composite < high:
                sentiment_desc = desc
                break
        
        # ç”Ÿæˆäº¤æ˜“ä¿¡å·
        if composite < 25:
            signal = "ğŸ”´ æåº¦ææƒ§ - å¯èƒ½æ˜¯ä¹°å…¥æœºä¼š"
        elif composite < 40:
            signal = "ğŸŸ  ææƒ§ - è€ƒè™‘åˆ†æ‰¹å»ºä»“"
        elif composite < 60:
            signal = "ğŸŸ¡ ä¸­æ€§ - è§‚æœ›æˆ–å°é¢å‚ä¸"
        elif composite < 80:
            signal = "ğŸŸ¢ è´ªå©ª - è€ƒè™‘è·åˆ©äº†ç»“"
        else:
            signal = "ğŸ”µ æåº¦è´ªå©ª - è­¦æƒ•å›è°ƒé£é™©"
        
        return {
            'overall': sentiment_desc,
            'score': round(composite, 2),
            'components': {
                'social_heat': social_score,
                'search_momentum': search_score,
                'onchain_signals': onchain_score,
                'volatility_sentiment': vol_score
            },
            'signal': signal,
            'timestamp': datetime.now().isoformat()
        }
    
    def export_report(self, output_path: str = None) -> str:
        """
        ç”Ÿæˆå¹¶å¯¼å‡ºæƒ…ç»ªåˆ†ææŠ¥å‘Š
        
        Args:
            output_path: å¯¼å‡ºè·¯å¾„ï¼Œé»˜è®¤ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶å
        
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        result = self.get_comprehensive_sentiment()
        
        if output_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f"sentiment_report_{timestamp}.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        return output_path


# ==================== æ•°æ®è·å–è¾…åŠ©å‡½æ•° ====================

def fetch_coingecko_price(coin_id: str = 'bitcoin', days: int = 30) -> List[float]:
    """
    ä»CoinGeckoè·å–å†å²ä»·æ ¼æ•°æ®
    
    Args:
        coin_id: å¸ç§ID (bitcoin, ethereum, etc.)
        days: è·å–å¤©æ•°
    
    Returns:
        ä»·æ ¼åˆ—è¡¨
    """
    url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart"
    params = {'vs_currency': 'usd', 'days': days}
    
    try:
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        prices = [p[1] for p in data.get('prices', [])]
        return prices
    except Exception as e:
        print(f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
        return []


def fetch_fear_greed_index() -> Optional[Dict]:
    """
    è·å–Alternative.meçš„ææƒ§è´ªå©ªæŒ‡æ•°ä½œä¸ºå¯¹æ¯”å‚è€ƒ
    
    Returns:
        åŒ…å«æŒ‡æ•°å€¼å’Œåˆ†ç±»çš„å­—å…¸
    """
    url = "https://api.alternative.me/fng/"
    
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        if data.get('data'):
            return {
                'value': int(data['data'][0]['value']),
                'classification': data['data'][0]['value_classification'],
                'timestamp': data['data'][0]['timestamp']
            }
    except Exception as e:
        print(f"è·å–ææƒ§è´ªå©ªæŒ‡æ•°å¤±è´¥: {e}")
    
    return None


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸª™ åŠ å¯†è´§å¸å¸‚åœºæƒ…ç»ªè¿½è¸ªå™¨ v1.0")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¿½è¸ªå™¨
    tracker = CryptoSentimentTracker()
    
    # è·å–ç»¼åˆæƒ…ç»ªåˆ†æ
    result = tracker.get_comprehensive_sentiment()
    
    print(f"\nğŸ“Š ç»¼åˆæƒ…ç»ª: {result['overall']}")
    print(f"ğŸ“ˆ æƒ…ç»ªå¾—åˆ†: {result['score']}/100")
    
    print(f"\nğŸ“‹ åˆ†é¡¹æŒ‡æ ‡:")
    for component, score in result['components'].items():
        bar = "â–ˆ" * int(score / 5) + "â–‘" * (20 - int(score / 5))
        print(f"   {component:20s} {bar} {score:.1f}")
    
    print(f"\nğŸ’¡ äº¤æ˜“ä¿¡å·: {result['signal']}")
    print(f"\nğŸ• ç”Ÿæˆæ—¶é—´: {result['timestamp']}")
    
    # å¯¹æ¯”å®˜æ–¹ææƒ§è´ªå©ªæŒ‡æ•°
    print("\n" + "-" * 60)
    official = fetch_fear_greed_index()
    if official:
        print(f"ğŸ“Š Alternative.me å®˜æ–¹ææƒ§è´ªå©ªæŒ‡æ•°: {official['value']} ({official['classification']})")
    
    # å¯¼å‡ºæŠ¥å‘Š
    report_path = tracker.export_report()
    print(f"\nğŸ“„ æŠ¥å‘Šå·²å¯¼å‡º: {report_path}")
